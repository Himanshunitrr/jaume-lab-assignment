{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63b9604a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FIRST PROMPT:\n",
    "\n",
    "# PROMPT_TEMPLATE = \"\"\"You are creating grounded, segmentation-aware captions for pathology tiles.\n",
    "\n",
    "# Image: {image_filename}\n",
    "\n",
    "# Tissue area (px): {tissue_px}\n",
    "\n",
    "# Region coverage (percentage of tissue area):\n",
    "# {region_lines}\n",
    "\n",
    "# Detected cell instances from the nucleus mask.\n",
    "# Each cell has a unique instance_id and a bounding box in pixel coordinates [x_min, y_min, x_max, y_max].\n",
    "# Cell instances:\n",
    "# {cell_lines}\n",
    "\n",
    "# TASK:\n",
    "# Write 1–2 fluent paragraphs that describe the image at a level suitable for a pathologist audience. \n",
    "# Ground every mention of structures explicitly using tags:\n",
    "#   • For tissue regions, append [REGION:{{region_id}}] after the mention (e.g., \"stromal areas [REGION:2]\").\n",
    "#   • For specific cell mentions tied to visible instances, append [CELL:{{instance_id}}] after the mention.\n",
    "#   • If you describe aggregate cell patterns (e.g., \"dense lymphocytic infiltrate\"), you may reference multiple instances like [CELL:{{id1}},CELL:{{id2}},CELL:{{id3}}].\n",
    "\n",
    "# CONSTRAINTS:\n",
    "#   • Do not invent categories not present in the label sets below.\n",
    "#   • Avoid clinical conclusions (diagnoses, grading); focus on visual description and composition.\n",
    "#   • Prefer precise, grounded language. If a region is <1% of tissue, describe it as sparse or rare.\n",
    "\n",
    "# REFERENCE LABELS:\n",
    "#   Regions: {region_label_map}\n",
    "#   Nuclei:  {nucleus_label_map}\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d74a48c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 image/mask pairs.\n",
      "Wrote 5 prompt(s) to claude_grounded_prompts.jsonl\n"
     ]
    }
   ],
   "source": [
    "# curate_claude_prompts.py\n",
    "# Python 3.9+\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Dict, Tuple, List\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from matplotlib.colors import rgb_to_hsv\n",
    "\n",
    "# ========== CONFIG ==========\n",
    "IMAGES_DIR = Path(\"/home/himanshu/Downloads/tcga-20251015T043235Z-1-002/tcga/images_512\")\n",
    "MASKS_DIR  = Path(\"/home/himanshu/Downloads/tcga-20251015T043235Z-1-002/tcga/masks_512\")\n",
    "PREV_JSON  = Path(\"exclude_over_tissue_div_tissue_area_gt10.json\")  # images in here will be SKIPPED\n",
    "OUT_JSONL  = Path(\"claude_grounded_prompts.jsonl\")\n",
    "\n",
    "IMG_EXTS   = {\".png\", \".jpg\", \".jpeg\", \".tif\", \".tiff\"}\n",
    "MASK_EXTS  = {\".png\"}\n",
    "NUM_SAMPLES_LIMIT = 5  # for testing, limit to first N samples\n",
    "# ---------- Label dictionaries (same as before) ----------\n",
    "REGION_LABELS: Dict[int, str] = {\n",
    "    0: \"Exclude\",\n",
    "    1: \"Cancerous epithelium\",\n",
    "    2: \"Stroma\",\n",
    "    3: \"TILs\",\n",
    "    4: \"Normal epithelium\",\n",
    "    5: \"Junk/Debris\",\n",
    "    6: \"Blood\",\n",
    "    7: \"Other\",\n",
    "    8: \"Whitespace/Empty\",\n",
    "}\n",
    "\n",
    "NUCLEUS_LABELS: Dict[int, str] = {\n",
    "    0: \"Exclude\",\n",
    "    1: \"Cancer nucleus\",\n",
    "    2: \"Stromal nucleus\",\n",
    "    3: \"Large stromal nucleus\",\n",
    "    4: \"Lymphocyte nucleus\",\n",
    "    5: \"Plasma/large TIL nucleus\",\n",
    "    6: \"Normal epithelial nucleus\",\n",
    "    7: \"Other nucleus\",\n",
    "    8: \"Unknown/Ambiguous nucleus\",\n",
    "    9: \"Background (non-nuclear material)\",\n",
    "}\n",
    "\n",
    "# Which nucleus values count as real cells (exclude backgrounds 0 & 9)\n",
    "NUCLEUS_VALID_VALUES = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "# ========== UTILITIES ==========\n",
    "def discover_pairs(images_dir: Path, masks_dir: Path) -> List[Tuple[Path, Path]]:\n",
    "    imgs = {p.stem: p for p in images_dir.iterdir() if p.suffix.lower() in IMG_EXTS}\n",
    "    msks = {p.stem: p for p in masks_dir.iterdir()  if p.suffix.lower() in MASK_EXTS}\n",
    "    keys = sorted(set(imgs) & set(msks))\n",
    "    return [(imgs[k], msks[k]) for k in keys]\n",
    "\n",
    "def load_rgb(path: Path) -> np.ndarray:\n",
    "    return np.array(Image.open(path).convert(\"RGB\"))\n",
    "\n",
    "def load_mask(path: Path) -> np.ndarray:\n",
    "    m = np.array(Image.open(path))\n",
    "    if m.ndim != 3 or m.shape[-1] != 3:\n",
    "        raise ValueError(f\"Mask must be (H,W,3). Got {m.shape} at {path}.\")\n",
    "    if not np.issubdtype(m.dtype, np.integer):\n",
    "        m = m.astype(np.uint8)\n",
    "    return m\n",
    "\n",
    "# ---------- Tissue via S-channel threshold ----------\n",
    "def otsu_threshold_01(img01: np.ndarray) -> float:\n",
    "    hist, bin_edges = np.histogram(img01.ravel(), bins=256, range=(0.0, 1.0))\n",
    "    hist = hist.astype(np.float64)\n",
    "    p = hist / (hist.sum() + 1e-12)\n",
    "    omega = np.cumsum(p)\n",
    "    mu = np.cumsum(p * np.arange(256))\n",
    "    mu_t = mu[-1]\n",
    "    denom = (omega * (1.0 - omega) + 1e-12)\n",
    "    sigma_b2 = (mu_t * omega - mu) ** 2 / denom\n",
    "    k_star = int(np.nanargmax(sigma_b2))\n",
    "    thr = (bin_edges[k_star] + bin_edges[k_star+1]) * 0.5\n",
    "    return float(np.clip(thr, 0.0, 1.0))\n",
    "\n",
    "def tissue_mask_from_S(rgb: np.ndarray, method: str = \"otsu\", fixed_thresh: float = 0.2) -> np.ndarray:\n",
    "    rgb01 = rgb.astype(np.float32) / 255.0\n",
    "    hsv = rgb_to_hsv(rgb01)\n",
    "    S = hsv[..., 1]\n",
    "    t = otsu_threshold_01(S) if method == \"otsu\" else float(fixed_thresh)\n",
    "    return S > t\n",
    "\n",
    "# ---------- Connected components with fallbacks ----------\n",
    "def connected_components_bool(mask_bool: np.ndarray) -> Tuple[np.ndarray, int]:\n",
    "    \"\"\"\n",
    "    Return (labels, num_labels) for a boolean mask.\n",
    "    Fallback chain: scipy.ndimage -> skimage.measure -> pure numpy BFS (slow but robust).\n",
    "    \"\"\"\n",
    "    try:\n",
    "        from scipy import ndimage as ndi\n",
    "        labels, num = ndi.label(mask_bool.astype(np.uint8), structure=np.ones((3,3), dtype=np.uint8))\n",
    "        return labels, int(num)\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        from skimage.measure import label as sk_label\n",
    "        labels = sk_label(mask_bool, connectivity=2)\n",
    "        return labels, int(labels.max())\n",
    "    except Exception:\n",
    "        pass\n",
    "    # Pure numpy BFS fallback\n",
    "    labels = np.zeros(mask_bool.shape, dtype=np.int32)\n",
    "    H, W = mask_bool.shape\n",
    "    num = 0\n",
    "    # 8-connected neighbors\n",
    "    neighbors = [(-1,-1),(-1,0),(-1,1),(0,-1),(0,1),(1,-1),(1,0),(1,1)]\n",
    "    visited = np.zeros_like(mask_bool, dtype=bool)\n",
    "    for y in range(H):\n",
    "        for x in range(W):\n",
    "            if mask_bool[y,x] and not visited[y,x]:\n",
    "                num += 1\n",
    "                stack = [(y,x)]\n",
    "                visited[y,x] = True\n",
    "                labels[y,x] = num\n",
    "                while stack:\n",
    "                    cy,cx = stack.pop()\n",
    "                    for dy,dx in neighbors:\n",
    "                        ny,nx = cy+dy, cx+dx\n",
    "                        if 0 <= ny < H and 0 <= nx < W and mask_bool[ny,nx] and not visited[ny,nx]:\n",
    "                            visited[ny,nx] = True\n",
    "                            labels[ny,nx] = num\n",
    "                            stack.append((ny,nx))\n",
    "    return labels, num\n",
    "\n",
    "def bboxes_from_cc_labels(labels: np.ndarray, num: int) -> List[Tuple[int,int,int,int]]:\n",
    "    \"\"\"\n",
    "    Given labeled components (1..num), return list of bounding boxes [x_min, y_min, x_max, y_max].\n",
    "    \"\"\"\n",
    "    boxes = []\n",
    "    for k in range(1, num+1):\n",
    "        ys, xs = np.where(labels == k)\n",
    "        if ys.size == 0:\n",
    "            boxes.append([0,0,0,0])\n",
    "            continue\n",
    "        y_min, y_max = int(ys.min()), int(ys.max())\n",
    "        x_min, x_max = int(xs.min()), int(xs.max())\n",
    "        boxes.append([x_min, y_min, x_max, y_max])\n",
    "    return boxes\n",
    "\n",
    "# ---------- Region coverage over tissue ----------\n",
    "def region_percentages_over_tissue(reg: np.ndarray, tissue: np.ndarray) -> Dict[int, float]:\n",
    "    tissue_px = int(tissue.sum())\n",
    "    if tissue_px == 0:\n",
    "        return {k: 0.0 for k in REGION_LABELS.keys()}\n",
    "    out = {}\n",
    "    for k in REGION_LABELS.keys():\n",
    "        if k in (0, 8):  # Exclude + Whitespace often not tissue; still compute objectively:\n",
    "            inter = int(((reg == k) & tissue).sum())\n",
    "            out[k] = 100.0 * inter / tissue_px\n",
    "        else:\n",
    "            inter = int(((reg == k) & tissue).sum())\n",
    "            out[k] = 100.0 * inter / tissue_px\n",
    "    return out\n",
    "\n",
    "# ---------- Build prompt text ----------\n",
    "PROMPT_TEMPLATE = \"\"\"\n",
    "You are an expert histopathology assistant.\n",
    "\n",
    "Your job has two phases:\n",
    "(1) Write the best possible description based **only on what is visually present in the image**.\n",
    "(2) Repeat that same text **verbatim**, but append grounding tags using the provided metadata (regions and detected nuclei instances). Use metadata strictly for tagging and light quantification; do not let it change the wording of the image-based description.\n",
    "\n",
    "# IMAGE + METADATA\n",
    "Image: {image_filename}\n",
    "Tissue area (px): {tissue_px}\n",
    "\n",
    "Region coverage (% of tissue area):\n",
    "{region_lines}\n",
    "\n",
    "Detected cell instances from the nucleus mask (each has unique instance_id and bbox [x_min, y_min, x_max, y_max] in px):\n",
    "{cell_lines}\n",
    "\n",
    "REFERENCE LABELS:\n",
    "  Regions: {region_label_map}\n",
    "  Nuclei:  {nucleus_label_map}\n",
    "\n",
    "# SILENT DELIBERATION (do not include in output)\n",
    "- IMAGE-FIRST: Build your description solely from visible evidence (architecture, interfaces, stroma, cellularity, distribution, cytologic features). Do not import labels or IDs into wording.\n",
    "- SALIENCE ORDER: (1) overall composition & dominant compartment(s); (2) architecture & interfaces; (3) stromal features; (4) cellularity & distribution (diffuse/focal/clustered); (5) cytology if clearly appreciable; (6) conspicuous negatives (e.g., no necrosis) if confidently visible; (7) notable artifacts if present.\n",
    "- QUANTIFY (if visually supportable): use approximate counts/percentages/densities that are visually reasonable; later you may refine with metadata **without** changing the prose.\n",
    "- SPATIAL LANGUAGE: use central/peripheral, adjacent to, interface/border, perivascular, subglandular, etc.\n",
    "- GROUNDING RULE: In the grounded copy, add tags only to entities already described from the image. Never invent mentions to satisfy metadata. If metadata lacks an ID for a described entity, leave it untagged.\n",
    "\n",
    "# OUTPUT (STRICT) — produce exactly these sections but give only the GROUNDED_DESCRIPTION\n",
    "\n",
    "DESCRIPTION\n",
    "Write 1–2 paragraphs of polished pathologist prose derived **only from the image**. Lead with dominant regions and composition; describe architecture and interfaces; summarize stromal qualities; characterize cellularity and distribution; add cytology only if clearly visible; include conspicuous negatives where appropriate. No IDs, no tags, no label names from metadata.\n",
    "\n",
    "GROUNDED_DESCRIPTION\n",
    "Repeat DESCRIPTION **verbatim**, but append grounding tags **inline after the first mention** of each corresponding entity:\n",
    "- Tissue regions → [REGION:{{region_id}}]\n",
    "- Specific single cells you explicitly reference → [CELL:{{instance_id}}]\n",
    "- Aggregate cellular patterns (e.g., “dense lymphocytic infiltrate”) → one tag listing all representative instances: [CELL:{{id1}},{{id2}},{{id3}}]\n",
    "Use only IDs present above. Do not alter wording. Do not invent tags.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def format_region_lines(region_pcts: Dict[int, float]) -> str:\n",
    "    lines = []\n",
    "    for k in sorted(region_pcts.keys()):\n",
    "        lines.append(f\"- {k}: {REGION_LABELS[k]} = {region_pcts[k]:.2f}%\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def format_cell_lines(instances: List[Dict]) -> str:\n",
    "    if not instances:\n",
    "        return \"- (no cell instances detected)\"\n",
    "    lines = []\n",
    "    for inst in instances:\n",
    "        lines.append(\n",
    "            f\"- CELL:{inst['instance_id']} | type={inst['cell_type_id']}({inst['cell_type_name']}) \"\n",
    "            f\"| bbox={inst['bbox']}\"\n",
    "        )\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "# ---------- Main curation ----------\n",
    "def curate_prompts(\n",
    "    images_dir: Path = IMAGES_DIR,\n",
    "    masks_dir: Path = MASKS_DIR,\n",
    "    prev_json: Path = PREV_JSON,\n",
    "    out_jsonl: Path = OUT_JSONL,\n",
    "    s_method: str = \"otsu\",\n",
    "    s_fixed_thresh: float = 0.2,\n",
    "    min_component_size: int = 5  # drop tiny specks (px)\n",
    "):\n",
    "    pairs = discover_pairs(images_dir, masks_dir)\n",
    "    pairs = pairs[:NUM_SAMPLES_LIMIT]  # for testing, limit to first N samples\n",
    "    \n",
    "    print(f\"Found {len(pairs)} image/mask pairs.\")\n",
    "\n",
    "    # Load the \"skip\" set from prev_json\n",
    "    skip_names = set()\n",
    "    if prev_json.exists():\n",
    "        try:\n",
    "            data = json.loads(prev_json.read_text())\n",
    "            for r in data.get(\"results\", []):\n",
    "                if \"filename\" in r:\n",
    "                    skip_names.add(r[\"filename\"])\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: could not parse {prev_json}: {e}\")\n",
    "\n",
    "    n_written = 0\n",
    "    with out_jsonl.open(\"w\") as fout:\n",
    "        for ipath, mpath in pairs:\n",
    "            if ipath.name in skip_names:\n",
    "                # Skip images that failed earlier criteria\n",
    "                continue\n",
    "\n",
    "            rgb = load_rgb(ipath)\n",
    "            m   = load_mask(mpath)\n",
    "            reg = m[..., 0]\n",
    "            nuc = m[..., 1]\n",
    "\n",
    "            # Tissue mask\n",
    "            tissue = tissue_mask_from_S(rgb, method=s_method, fixed_thresh=s_fixed_thresh)\n",
    "            tissue_px = int(tissue.sum())\n",
    "\n",
    "            # Region coverage (as % of tissue)\n",
    "            region_pcts = region_percentages_over_tissue(reg, tissue)\n",
    "\n",
    "            # Nucleus instances (per valid class)\n",
    "            instances = []\n",
    "            next_id = 1\n",
    "            H, W = nuc.shape\n",
    "            for val in NUCLEUS_VALID_VALUES:\n",
    "                class_mask = (nuc == val)\n",
    "                if not class_mask.any():\n",
    "                    continue\n",
    "                # restrict to tissue to avoid whitespace specks\n",
    "                class_mask = class_mask & tissue\n",
    "                if not class_mask.any():\n",
    "                    continue\n",
    "\n",
    "                labels, num = connected_components_bool(class_mask)\n",
    "                if num == 0:\n",
    "                    continue\n",
    "\n",
    "                # Optional: remove tiny components\n",
    "                # Compute sizes and filter\n",
    "                sizes = np.bincount(labels.ravel())\n",
    "                # sizes[0] is background\n",
    "                keep = np.where(sizes >= max(min_component_size, 1))[0]\n",
    "                keep = keep[keep != 0]\n",
    "\n",
    "                if keep.size == 0:\n",
    "                    continue\n",
    "\n",
    "                # Create mask with only kept components\n",
    "                kept_mask = np.isin(labels, keep)\n",
    "                kept_labels, kept_num = connected_components_bool(kept_mask)\n",
    "\n",
    "                boxes = bboxes_from_cc_labels(kept_labels, kept_num)\n",
    "                for k in range(1, kept_num + 1):\n",
    "                    ys, xs = np.where(kept_labels == k)\n",
    "                    if ys.size == 0:\n",
    "                        continue\n",
    "                    y_min, y_max = int(ys.min()), int(ys.max())\n",
    "                    x_min, x_max = int(xs.min()), int(xs.max())\n",
    "                    instances.append({\n",
    "                        \"instance_id\": next_id,\n",
    "                        \"cell_type_id\": int(val),\n",
    "                        \"cell_type_name\": NUCLEUS_LABELS[val],\n",
    "                        \"bbox\": [x_min, y_min, x_max, y_max],\n",
    "                        \"area_px\": int(ys.size),\n",
    "                    })\n",
    "                    next_id += 1\n",
    "\n",
    "            # Build the prompt text\n",
    "            prompt_text = PROMPT_TEMPLATE.format(\n",
    "                image_filename=ipath.name,\n",
    "                tissue_px=tissue_px,\n",
    "                region_lines=format_region_lines(region_pcts),\n",
    "                cell_lines=format_cell_lines(instances),\n",
    "                region_label_map=json.dumps(REGION_LABELS, ensure_ascii=False),\n",
    "                nucleus_label_map=json.dumps(NUCLEUS_LABELS, ensure_ascii=False),\n",
    "            )\n",
    "\n",
    "            # Write one JSONL record per image\n",
    "            record = {\n",
    "                \"image_path\": str(ipath),\n",
    "                \"metadata\": {\n",
    "                    \"tissue_px\": tissue_px,\n",
    "                    \"region_percent_over_tissue\": {str(k): round(v, 4) for k, v in region_pcts.items()},\n",
    "                    \"cell_instances\": instances,  # list of dicts with instance_id, type, bbox, area_px\n",
    "                    \"region_labels\": REGION_LABELS,\n",
    "                    \"nucleus_labels\": NUCLEUS_LABELS,\n",
    "                },\n",
    "                \"prompt\": prompt_text,\n",
    "            }\n",
    "            fout.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "            n_written += 1\n",
    "\n",
    "    print(f\"Wrote {n_written} prompt(s) to {out_jsonl}\")\n",
    "\n",
    "# ---------- Run ----------\n",
    "if __name__ == \"__main__\":\n",
    "    curate_prompts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec10fceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5 prompts; wrote 5 responses to claude_grounded_prompts_with_responses.jsonl\n"
     ]
    }
   ],
   "source": [
    "# send_to_claude.py\n",
    "# Python 3.9+\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "# pip install anthropic==0.* (current SDK)\n",
    "import anthropic\n",
    "from anthropic.types import Message\n",
    "\n",
    "IN_JSONL  = Path(\"claude_grounded_prompts.jsonl\")\n",
    "OUT_JSONL = Path(\"claude_grounded_prompts_with_responses.jsonl\")\n",
    "\n",
    "# Choose your model; update if you prefer a smaller/cheaper one\n",
    "CLAUDE_MODEL = os.getenv(\"CLAUDE_MODEL\", \"claude-3-5-sonnet-latest\")\n",
    "\n",
    "# Safety knobs\n",
    "MAX_RETRIES = 5\n",
    "INITIAL_BACKOFF_S = 2.0\n",
    "RATE_LIMIT_DELAY_S = float(os.getenv(\"CLAUDE_RATE_DELAY_S\", \"0.0\"))  # e.g., 0.5 to throttle\n",
    "\n",
    "def call_claude(\n",
    "    client: anthropic.Anthropic,\n",
    "    prompt_text: str,\n",
    "    max_tokens: int = 2048\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Calls Claude Messages API with your prompt text and returns the string content.\n",
    "    \"\"\"\n",
    "    backoff = INITIAL_BACKOFF_S\n",
    "    for attempt in range(1, MAX_RETRIES + 1):\n",
    "        try:\n",
    "            msg: Message = client.messages.create(\n",
    "                model=CLAUDE_MODEL,\n",
    "                max_tokens=max_tokens,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt_text}],\n",
    "            )\n",
    "            # Messages API returns a list of content blocks; join text blocks\n",
    "            parts = []\n",
    "            for block in msg.content:\n",
    "                if block.type == \"text\":\n",
    "                    parts.append(block.text)\n",
    "            return \"\\n\".join(parts).strip()\n",
    "        except anthropic.RateLimitError as e:\n",
    "            # Hit org/project rate limits: back off\n",
    "            if attempt == MAX_RETRIES:\n",
    "                raise\n",
    "            time.sleep(backoff)\n",
    "            backoff *= 2\n",
    "        except anthropic.APIError as e:\n",
    "            # Transient server errors: retry with backoff\n",
    "            if getattr(e, \"status_code\", 500) >= 500 and attempt < MAX_RETRIES:\n",
    "                time.sleep(backoff)\n",
    "                backoff *= 2\n",
    "                continue\n",
    "            raise\n",
    "NUM_SAMPLES_LIMIT = 5  # for testing, limit to first N samples\n",
    "def main():\n",
    "    api_key = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "    if not api_key:\n",
    "        raise RuntimeError(\"Set ANTHROPIC_API_KEY in your environment.\")\n",
    "\n",
    "    client = anthropic.Anthropic(api_key=api_key)\n",
    "\n",
    "    if not IN_JSONL.exists():\n",
    "        raise FileNotFoundError(f\"Input JSONL not found: {IN_JSONL}\")\n",
    "\n",
    "    n_in, n_out = 0, 0\n",
    "    with IN_JSONL.open(\"r\") as fin, OUT_JSONL.open(\"w\") as fout:\n",
    "        for i, line in enumerate(fin):\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            n_in += 1\n",
    "            record = json.loads(line)\n",
    "\n",
    "            prompt_text = record.get(\"prompt\", \"\")\n",
    "            if not prompt_text:\n",
    "                # Nothing to send—skip\n",
    "                continue\n",
    "\n",
    "            # Optional: throttle to be nice to rate limits\n",
    "            if RATE_LIMIT_DELAY_S > 0:\n",
    "                time.sleep(RATE_LIMIT_DELAY_S)\n",
    "\n",
    "            response_text = call_claude(client, prompt_text, max_tokens=1200)\n",
    "\n",
    "            out_rec = {\n",
    "                **record,\n",
    "                \"claude\": {\n",
    "                    \"model\": CLAUDE_MODEL,\n",
    "                    \"response\": response_text,\n",
    "                },\n",
    "            }\n",
    "            fout.write(json.dumps(out_rec, ensure_ascii=False) + \"\\n\")\n",
    "            n_out += 1\n",
    "\n",
    "            if i == NUM_SAMPLES_LIMIT - 1:\n",
    "                # For testing, limit to first 10 prompts\n",
    "                break\n",
    "\n",
    "    print(f\"Processed {n_in} prompts; wrote {n_out} responses to {OUT_JSONL}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lavida",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
